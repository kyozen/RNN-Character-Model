{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WIP_5-RNN-CharacterRNN-theano.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/kyozen/RNN-Character-Model/blob/master/WIP_5_RNN_CharacterRNN_theano.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "cZmZo-xlvwAc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "RNN Character Model\n",
        "===========\n",
        "\n",
        "This example trains a RNN to predict the next character in a sequence, and was created by Eben Olson (see : https://github.com/ebenolson/pydata2015). Sampling from the trained model produces somewhat intelligible text, with vocabulary and style resembling the training corpus. For more background and details:\n",
        "- http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
        "- https://github.com/karpathy/char-rnn\n",
        "\n",
        "The data used for training is one of :\n",
        "  *  a collection of patent claims obtained from http://www.cl.uni-heidelberg.de/statnlpgroup/pattr/\n",
        "  *  Shakespeare's plays\n",
        "  *  Shakespeare's poetry\n",
        "  \n",
        "For an alternative implementation in Keras, see : https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py"
      ]
    },
    {
      "metadata": {
        "id": "0-lNQkeAvwAg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import theano\n",
        "import theano.tensor as T\n",
        "\n",
        "import lasagne\n",
        "from lasagne.utils import floatX\n",
        "\n",
        "import pickle\n",
        "import gzip\n",
        "import random\n",
        "\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w_fVe6eVvwAj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load an interesting corpus :\n",
        "\n",
        "corpus = gzip.open('../data/RNN/claims.txt.gz').read()\n",
        "#corpus = gzip.open('../data/RNN/Shakespeare.plays.txt.gz').read()\n",
        "#corpus = gzip.open('../data/RNN/Shakespeare.poetry.txt.gz').read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FljYDOozvwAm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "corpus.split('\\n')[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YGPF3z1xvwAo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Network Parameters from Corpus\n",
        "Find the set of characters used in the corpus and construct mappings between characters, integer indices, and one hot encodings"
      ]
    },
    {
      "metadata": {
        "id": "4KNV5Lt7vwAp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "VOCABULARY = set(corpus)\n",
        "VOCAB_SIZE = len(VOCABULARY)\n",
        "\n",
        "CHAR_TO_IX = {c: i for i, c in enumerate(VOCABULARY)}\n",
        "IX_TO_CHAR = {i: c for i, c in enumerate(VOCABULARY)}\n",
        "CHAR_TO_ONEHOT = {c: np.eye(VOCAB_SIZE)[i] for i, c in enumerate(VOCABULARY)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JZxDEXuevwAr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "SEQUENCE_LENGTH = 50\n",
        "BATCH_SIZE = 64\n",
        "RNN_HIDDEN_SIZE = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qSnlc2djvwAt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create Training and Validation datasets\n",
        "And a 'batch generator' function that delivers data in the right format for RNN training"
      ]
    },
    {
      "metadata": {
        "id": "NkBTgNWKvwAu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Reserve 10% of the data for validation\n",
        "train_corpus = corpus[:(len(corpus) * 9 // 10)]\n",
        "val_corpus = corpus[(len(corpus) * 9 // 10):]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Hvox8H9vwAw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Our batch generator will yield sequential portions of the corpus of size SEQUENCE_LENGTH,\n",
        "# starting from random locations and wrapping around the end of the data.\n",
        "def data_batch_generator(corpus, size=BATCH_SIZE):\n",
        "    startidx = np.random.randint(0, len(corpus) - SEQUENCE_LENGTH - 1, size=size)\n",
        "\n",
        "    while True:\n",
        "        items = np.array([corpus[start:start + SEQUENCE_LENGTH + 1] for start in startidx])\n",
        "        startidx = (startidx + SEQUENCE_LENGTH) % (len(corpus) - SEQUENCE_LENGTH - 1)\n",
        "        yield items"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jLLDJr4XvwAy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Test it out\n",
        "gen = data_batch_generator(corpus, size=1)\n",
        "print(next(gen))\n",
        "print(next(gen))\n",
        "print(next(gen))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Csc9y-LvwA1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# After sampling a data batch, we transform it into a one hot feature representation\n",
        "# and create a target sequence by shifting by one character\n",
        "def prep_batch_for_network(batch):\n",
        "    x_seq = np.zeros((len(batch), SEQUENCE_LENGTH, VOCAB_SIZE), dtype='float32')\n",
        "    y_seq = np.zeros((len(batch), SEQUENCE_LENGTH), dtype='int32')\n",
        "\n",
        "    for i, item in enumerate(batch):\n",
        "        for j in range(SEQUENCE_LENGTH):\n",
        "            x_seq[i, j] = CHAR_TO_ONEHOT[ item[j] ]\n",
        "            #x_seq[i, j, :] = CHAR_TO_ONEHOT[ item[j] ]\n",
        "            y_seq[i, j] = CHAR_TO_IX[ item[j+1] ]\n",
        "\n",
        "    return x_seq, y_seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OMeMAByzvwA5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define the Network Symbolically"
      ]
    },
    {
      "metadata": {
        "id": "BBdEZcS9vwA6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Symbolic variables for input. In addition to the usual features and target,\n",
        "# we need initial values for the RNN layer's hidden states\n",
        "x_sym = T.tensor3()\n",
        "y_sym = T.imatrix()\n",
        "hid_init_sym = T.matrix()\n",
        "hid2_init_sym = T.matrix()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1OgGy6K3vwA9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Our network has two stacked GRU layers processing the input sequence.\n",
        "l_input = lasagne.layers.InputLayer((None, SEQUENCE_LENGTH, VOCAB_SIZE))\n",
        "l_input_hid = lasagne.layers.InputLayer((None, RNN_HIDDEN_SIZE))\n",
        "l_input_hid2 = lasagne.layers.InputLayer((None, RNN_HIDDEN_SIZE))\n",
        "\n",
        "l_rnn = lasagne.layers.GRULayer(l_input,\n",
        "                                  num_units=RNN_HIDDEN_SIZE,\n",
        "                                  grad_clipping=5.,\n",
        "                                  hid_init=l_input_hid,\n",
        "                                  #learn_init=True,\n",
        "                                  )\n",
        "\n",
        "l_rnn2 = lasagne.layers.GRULayer(l_rnn,\n",
        "                                  num_units=RNN_HIDDEN_SIZE,\n",
        "                                  grad_clipping=5.,\n",
        "                                  hid_init=l_input_hid2,\n",
        "                                  #learn_init=True,\n",
        "                                  )\n",
        "\n",
        "# Before the decoder layer, we need to reshape the sequence into the batch dimension,\n",
        "# so that timesteps are decoded independently.\n",
        "l_shp = lasagne.layers.ReshapeLayer(l_rnn2, (-1, RNN_HIDDEN_SIZE))\n",
        "\n",
        "l_decoder = lasagne.layers.DenseLayer(l_shp,\n",
        "                                      num_units=VOCAB_SIZE,\n",
        "                                      nonlinearity=lasagne.nonlinearities.softmax)\n",
        "\n",
        "l_out = lasagne.layers.ReshapeLayer(l_decoder, (-1, SEQUENCE_LENGTH, VOCAB_SIZE))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "snQIqiQivwA-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# We extract the hidden state of each GRU layer as well as the output of the decoder.\n",
        "# Only the hidden state at the last timestep is needed\n",
        "hid_out, hid2_out, prob_out = lasagne.layers.get_output([l_rnn, l_rnn2, l_out],\n",
        "                                                        {l_input: x_sym,\n",
        "                                                         l_input_hid: hid_init_sym,\n",
        "                                                         l_input_hid2: hid2_init_sym,\n",
        "                                                        })\n",
        "\n",
        "hid_out_last  = hid_out[:, -1]\n",
        "hid2_out_last = hid2_out[:, -1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S2uNhriovwBB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Loss Function for Training"
      ]
    },
    {
      "metadata": {
        "id": "HBvGnFQFvwBB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# We flatten the sequence into the batch dimension before calculating the loss\n",
        "def calc_cross_ent(net_output, targets):\n",
        "    preds = T.reshape(net_output, (-1, VOCAB_SIZE))\n",
        "    targets = T.flatten(targets)\n",
        "    cost = T.nnet.categorical_crossentropy(preds, targets)\n",
        "    return cost\n",
        "\n",
        "loss = T.mean(calc_cross_ent(prob_out, y_sym))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X5TwleEevwBD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# For stability during training, gradients are clipped and a total gradient norm constraint is also used\n",
        "MAX_GRAD_NORM = 15\n",
        "\n",
        "all_params = lasagne.layers.get_all_params(l_out, trainable=True)\n",
        "\n",
        "param_values = lasagne.layers.get_all_param_values(l_out)\n",
        "param_dictionary = {'param values': param_values,\n",
        "     'VOCABULARY': VOCABULARY, \n",
        "     'CHAR_TO_IX': CHAR_TO_IX,\n",
        "     'IX_TO_CHAR': IX_TO_CHAR,\n",
        "    }\n",
        "\n",
        "all_grads = T.grad(loss, all_params)\n",
        "all_grads = [T.clip(g, -5, 5) for g in all_grads]\n",
        "all_grads, norm = lasagne.updates.total_norm_constraint(\n",
        "    all_grads, MAX_GRAD_NORM, return_norm=True)\n",
        "\n",
        "updates = lasagne.updates.adam(all_grads, all_params, learning_rate=0.002)\n",
        "\n",
        "f_train = theano.function([x_sym, y_sym, hid_init_sym, hid2_init_sym],\n",
        "                          [loss, norm, hid_out_last, hid2_out_last],\n",
        "                          updates=updates\n",
        "                         )\n",
        "\n",
        "f_val = theano.function([x_sym, y_sym, hid_init_sym, hid2_init_sym], [loss, hid_out_last, hid2_out_last])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "skFX7eqbvwBF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Finally, the Training Loop\n",
        "\n",
        "Training takes a while :: 100 iteration takes about 2 minutes on a CPU (so, overall, it could be HOURS without a GPU)\n",
        "\n",
        "... you may want to skip this and the next cell, and load the pretrained weights instead"
      ]
    },
    {
      "metadata": {
        "id": "iCB73rfmvwBG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hid = np.zeros((BATCH_SIZE, RNN_HIDDEN_SIZE), dtype='float32')\n",
        "hid2 = np.zeros((BATCH_SIZE, RNN_HIDDEN_SIZE), dtype='float32')\n",
        "\n",
        "train_batch_gen = data_batch_generator(train_corpus)\n",
        "\n",
        "for iteration in range(2*100*100):\n",
        "    x, y = prep_batch_for_network(next(train_batch_gen))\n",
        "    #print(iteration, np.shape(x), np.shape(y), np.shape(hid), np.shape(hid2))\n",
        "    loss_train, norm, hid, hid2 = f_train(x, y, hid, hid2)\n",
        "    \n",
        "    if iteration % 100 == 0:\n",
        "        print('Iteration {}, loss_train: {}, norm: {}'.format(iteration, loss_train, norm))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SHYiskJnvwBI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Save the learned parameters\n",
        "\n",
        "Uncomment the ```pickle.dump()``` to actually save to disk"
      ]
    },
    {
      "metadata": {
        "id": "NursURLtvwBJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#pickle.dump(param_dictionary, open('./data/RNN/gru_2layer_trained.pkl','w'), protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "njkN-jYevwBL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load pretrained weights into network"
      ]
    },
    {
      "metadata": {
        "id": "TXGJwPlNvwBL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "param_dictionary = pickle.load(open('./data/RNN/gru_2layer_trained_claims.pkl', 'r'))\n",
        "lasagne.layers.set_all_param_values(l_out, param_dictionary['param values'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_VDKfDwQvwBP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Produce a Validation Score"
      ]
    },
    {
      "metadata": {
        "id": "ftmWXm7kvwBR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predict_fn = theano.function([x_sym, hid_init_sym, hid2_init_sym], [prob_out, hid_out_last, hid2_out_last])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-YnoGrNyvwBU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Calculate validation loss (this takes a minute or so on a CPU)\n",
        "hid = np.zeros((BATCH_SIZE, RNN_HIDDEN_SIZE), dtype='float32')\n",
        "hid2 = np.zeros((BATCH_SIZE, RNN_HIDDEN_SIZE), dtype='float32')\n",
        "\n",
        "val_batch_gen = data_batch_generator(val_corpus)\n",
        "\n",
        "losses = []\n",
        "\n",
        "for iteration in range(50):\n",
        "    x, y = prep_batch_for_network(next(val_batch_gen))\n",
        "    #print(iteration, np.shape(x), np.shape(y), np.shape(hid), np.shape(hid2))\n",
        "    loss_val, hid, hid2 = f_val(x, y, hid, hid2)\n",
        "    losses.append(loss_val)\n",
        "    \n",
        "print(np.mean(losses))  # Preloaded data gives a result of 0.89385"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EWT-3BeZvwBX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create a network that's optimised to *produce* text\n",
        "\n",
        "For faster sampling, we rebuild the network with a sequence length of 1"
      ]
    },
    {
      "metadata": {
        "id": "nn2Hq5tfvwBZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "l_input = lasagne.layers.InputLayer((None, 1, VOCAB_SIZE))\n",
        "l_input_hid = lasagne.layers.InputLayer((None, RNN_HIDDEN_SIZE))\n",
        "l_input_hid2 = lasagne.layers.InputLayer((None, RNN_HIDDEN_SIZE))\n",
        "\n",
        "l_rnn = lasagne.layers.GRULayer(l_input,\n",
        "                                  num_units=RNN_HIDDEN_SIZE,\n",
        "                                  grad_clipping=5.,\n",
        "                                  hid_init=l_input_hid,\n",
        "                                  )\n",
        "\n",
        "l_rnn2 = lasagne.layers.GRULayer(l_rnn,\n",
        "                                  num_units=RNN_HIDDEN_SIZE,\n",
        "                                  grad_clipping=5.,\n",
        "                                  hid_init=l_input_hid2,\n",
        "                                  )\n",
        "\n",
        "\n",
        "l_shp = lasagne.layers.ReshapeLayer(l_rnn2, (-1, RNN_HIDDEN_SIZE))\n",
        "\n",
        "l_decoder = lasagne.layers.DenseLayer(l_shp,\n",
        "                                      num_units=VOCAB_SIZE,\n",
        "                                      nonlinearity=lasagne.nonlinearities.softmax)\n",
        "\n",
        "l_out = lasagne.layers.ReshapeLayer(l_decoder, (-1, 1, VOCAB_SIZE))\n",
        "\n",
        "hid_out, hid2_out, prob_out = lasagne.layers.get_output([l_rnn, l_rnn2, l_out], {\n",
        "                                                         l_input: x_sym,\n",
        "                                                         l_input_hid: hid_init_sym,\n",
        "                                                         l_input_hid2: hid2_init_sym,\n",
        "                                                        })\n",
        "hid_out_last  = hid_out[:, -1]\n",
        "hid2_out_last = hid2_out[:, -1]\n",
        "prob_out_last = prob_out[0, -1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n4PzwjY1vwBd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lasagne.layers.set_all_param_values(l_out, param_dictionary['param values'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pVSeR1pzvwBg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predict_fn = theano.function([x_sym, hid_init_sym, hid2_init_sym], [prob_out_last, hid_out_last, hid2_out_last])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DGLkPnq9vwBi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Finally, Produce some text\n",
        "We will use random sentences from the validation corpus to 'prime' the network"
      ]
    },
    {
      "metadata": {
        "id": "PWtDOBmDvwBi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "primers = val_corpus.split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ldApsnt9vwBk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We feed characters one at a time from the priming sequence into the network.\n",
        "\n",
        "To obtain a sample string, at each timestep we sample from the output probability distribution, and feed the chosen character back into the network. We terminate after the first linebreak."
      ]
    },
    {
      "metadata": {
        "id": "QV-71dgavwBl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentence = ''\n",
        "hid = np.zeros((1, RNN_HIDDEN_SIZE), dtype='float32')\n",
        "hid2 = np.zeros((1, RNN_HIDDEN_SIZE), dtype='float32')\n",
        "x = np.zeros((1, 1, VOCAB_SIZE), dtype='float32')\n",
        "\n",
        "primer = np.random.choice(primers) + '\\n'\n",
        "\n",
        "for c in primer:\n",
        "    p, hid, hid2 = predict_fn(x, hid, hid2)\n",
        "    x[0, 0, :] = CHAR_TO_ONEHOT[c]\n",
        "    \n",
        "for _ in range(500):\n",
        "    p, hid, hid2 = predict_fn(x, hid, hid2)\n",
        "    p = p/(1 + 1e-6)\n",
        "    s = np.random.multinomial(1, p)\n",
        "    sentence += IX_TO_CHAR[s.argmax(-1)]\n",
        "    x[0, 0, :] = s\n",
        "    if sentence[-1] == '\\n':\n",
        "        break\n",
        "        \n",
        "print('PRIMER: ' + primer)\n",
        "print('GENERATED: ' + sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GU44RnSMvwBn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Exercises\n",
        "=====\n",
        "\n",
        "1. Implement sampling using the \"temperature softmax\": $$p(i) = \\frac{e^{\\frac{z_i}{T}}}{\\Sigma_k e^{\\frac{z_k}{T}}}$$\n",
        "\n",
        "This generalizes the softmax with a parameter $T$ which affects the \"sharpness\" of the distribution. Lowering $T$ will make samples less error-prone but more repetitive. "
      ]
    },
    {
      "metadata": {
        "id": "Ht0osgh9vwBn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Uncomment and run this cell for a solution\n",
        "#%load model/spoilers/tempsoftmax.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EbIVMnUtvwBp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}